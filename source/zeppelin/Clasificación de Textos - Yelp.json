{"paragraphs":[{"text":"%md\n# Clasificación de Textos - Yelp!\n\n## Introducción\nEn este Notebook se realiza una clasificación de textos del dataset de Yelp!.\nDe este dataset, se utiliza el fichero review.json el cual contiene el conjunto de opiniones de los distintos clientes y el número de \"estrellas\" asignados. El objetivo es a partir del texto poder predecir el número de estrellas a asignar, lo cual corresponde a una clasificación basada en el sentimiento.","user":"anonymous","dateUpdated":"2019-07-22T14:48:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Clasificación de Textos - Yelp!</h1>\n<h2>Introducción</h2>\n<p>En este Notebook se realiza una clasificación de textos del dataset de Yelp!.<br/>De este dataset, se utiliza el fichero review.json el cual contiene el conjunto de opiniones de los distintos clientes y el número de &ldquo;estrellas&rdquo; asignados. El objetivo es a partir del texto poder predecir el número de estrellas a asignar, lo cual corresponde a una clasificación basada en el sentimiento.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806858597_996943594","id":"20190722-144738_1737561871","dateCreated":"2019-07-22T14:47:38+0000","dateStarted":"2019-07-22T14:48:50+0000","dateFinished":"2019-07-22T14:48:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:169"},{"text":"%md\n## Desarrollos\nA continuación se realizan los desarrollos los cuales se dividen en dos partes:\n1. Pre-procesamiento: Se procede a la lectura y seleccion de variables así como la división del dataset en training y test (90%-10%)\n2. Entrenamiento: Se realizan el entrenamiento de los distintos modelos","user":"anonymous","dateUpdated":"2019-07-22T18:21:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Desarrollos</h2>\n<p>A continuación se realizan los desarrollos los cuales se dividen en dos partes:<br/>1. Pre-procesamiento: Se procede a la lectura y seleccion de variables así como la división del dataset en training y test (90%-10%)<br/>2. Entrenamiento: Se realizan el entrenamiento de los distintos modelos</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806942314_303771066","id":"20190722-144902_191725367","dateCreated":"2019-07-22T14:49:02+0000","dateStarted":"2019-07-22T18:21:07+0000","dateFinished":"2019-07-22T18:21:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:170"},{"text":"%md\n### Pre-processing\nSe realiza le pre-procesamiento de la información, el cual está dividido en:\n\n1. Lectura del dataset\n2. Selección de variables\n3. Eliminación de catacteres especiales y paso a lowercase\n","user":"anonymous","dateUpdated":"2019-07-22T18:21:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Pre-processing</h3>\n<p>Se realiza le pre-procesamiento de la información, el cual está dividido en:</p>\n<ol>\n  <li>Lectura del dataset</li>\n  <li>Selección de variables</li>\n  <li>Eliminación de catacteres especiales y paso a lowercase</li>\n</ol>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806972359_7659668","id":"20190722-144932_154089826","dateCreated":"2019-07-22T14:49:32+0000","dateStarted":"2019-07-22T18:21:19+0000","dateFinished":"2019-07-22T18:21:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:171"},{"text":"import org.apache.spark.ml.{PipelineModel, Pipeline}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.sql.DataFrame","user":"anonymous","dateUpdated":"2019-07-22T14:40:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563805375150_1470694872","id":"20190722-142255_1571162744","dateCreated":"2019-07-22T14:22:55+0000","dateStarted":"2019-07-22T14:40:16+0000","dateFinished":"2019-07-22T14:40:18+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:172"},{"text":"def evaluate(model: PipelineModel, test: DataFrame): Unit = {\n    // Select (prediction, true label) and compute test error.\n    val evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"label\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\")\n    // Make predictions.\n    val predictions = model.transform(test)\n\n    println(s\"Test set accuracy = ${evaluator.evaluate(predictions)}\")\n}","user":"anonymous","dateUpdated":"2019-07-22T14:27:05+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563805371137_-1751225575","id":"20190722-142251_1633935191","dateCreated":"2019-07-22T14:22:51+0000","dateStarted":"2019-07-22T14:27:05+0000","dateFinished":"2019-07-22T14:27:06+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"text":"def readData(path: String): (DataFrame, DataFrame) = {\n    import spark.sqlContext.implicits._\n    val data =spark.read.json(path)\n        // Se seleccionan las columnas necesarias\n        .select(\"text\", \"stars\")\n        .withColumnRenamed(\"stars\", \"label\")\n        .rdd\n        .map{\n            row =>\n                val t = row.getAs[String](\"text\")\n                val label = row.getAs[Double](\"label\")\n                // Se eliminan carácteres especiales\n                (t.toLowerCase.replaceAll(\"-?|\\\\/#@!\", \"\").split(\" \"), label)\n        }\n        .toDF(\"text\", \"label\")\n\n    val Array(training, test) = data.randomSplit(Array(0.8, 0.2), seed = 12345)\n    // Se utiliza la sentencia cache para alojar los datos en memoria y que procese más rápido al no tener que ir a disco.\n    training.chache()\n    test.cache()\n    return (training, test)\n}","user":"anonymous","dateUpdated":"2019-07-22T18:22:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563805594351_-60347343","id":"20190722-142634_1278944324","dateCreated":"2019-07-22T14:26:34+0000","dateStarted":"2019-07-22T18:22:30+0000","dateFinished":"2019-07-22T18:22:31+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:174"},{"text":"%md\n### Vectorización\nA continuación, se generan los algoritmos de vectorización que son el hashingTF y el IDF, con el objetivo de usarlos luego en el Pipeline a crear para cada uno de los modelos.  \nMediante estos algoritmos es posible extraer las características generando un vector con las palabras de cada texto.","user":"anonymous","dateUpdated":"2019-07-22T18:23:40+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","title":false,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Vectorización</h3>\n<p>A continuación, se generan los algoritmos de vectorización que son el hashingTF y el IDF, con el objetivo de usarlos luego en el Pipeline a crear para cada uno de los modelos.<br/>Mediante estos algoritmos es posible extraer las características generando un vector con las palabras de cada texto.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563805969339_-819734716","id":"20190722-143249_1845739246","dateCreated":"2019-07-22T14:32:49+0000","dateStarted":"2019-07-22T18:23:40+0000","dateFinished":"2019-07-22T18:23:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:175"},{"text":"import org.apache.spark.ml.feature.{HashingTF, IDF}\n","user":"anonymous","dateUpdated":"2019-07-22T14:39:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806338710_-1430471326","id":"20190722-143858_1508114827","dateCreated":"2019-07-22T14:38:58+0000","dateStarted":"2019-07-22T14:39:19+0000","dateFinished":"2019-07-22T14:39:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:176"},{"text":"val hashingTF = new HashingTF()\n      .setInputCol(\"text\")\n      .setOutputCol(\"countvec\")\n\n\nval idf = new IDF()\n  .setInputCol(hashingTF.getOutputCol)\n  .setOutputCol(\"features\")","user":"anonymous","dateUpdated":"2019-07-22T14:39:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563805781867_1844956162","id":"20190722-142941_1013323627","dateCreated":"2019-07-22T14:29:41+0000","dateStarted":"2019-07-22T14:39:22+0000","dateFinished":"2019-07-22T14:39:26+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:177"},{"text":"val (training, test) = readData(\"\")","user":"anonymous","dateUpdated":"2019-07-22T14:41:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806478738_-1570272773","id":"20190722-144118_799777284","dateCreated":"2019-07-22T14:41:18+0000","dateStarted":"2019-07-22T14:41:37+0000","dateFinished":"2019-07-22T14:41:43+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:178"},{"text":"%md\n### Algoritmos\nEn este apartado se realizan los entrenamientos de los distintos modelos. ","user":"anonymous","dateUpdated":"2019-07-22T18:24:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Algoritmos</h3>\n<p>En este apartado se realizan los entrenamientos de los distintos modelos.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806207174_-1222227866","id":"20190722-143647_1184574382","dateCreated":"2019-07-22T14:36:47+0000","dateStarted":"2019-07-22T18:24:32+0000","dateFinished":"2019-07-22T18:24:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:179"},{"text":"%md\n#### Naive Bayes\nPara la realización de este entrenamiento es necesario modificar el valor de la variable ModelType del modelo a multinomial dado que existen un total de 5 clases a clasificar, por lo que no es una clasificación binaria.","user":"anonymous","dateUpdated":"2019-07-22T18:25:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Naive Bayes</h4>\n<p>Para la realización de este entrenamiento es necesario modificar el valor de la variable ModelType del modelo a multinomial dado que existen un total de 5 clases a clasificar, por lo que no es una clasificación binaria.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806229407_-1288918806","id":"20190722-143709_596297085","dateCreated":"2019-07-22T14:37:09+0000","dateStarted":"2019-07-22T18:25:33+0000","dateFinished":"2019-07-22T18:25:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:180"},{"text":"import org.apache.spark.ml.classification.NaiveBayes\n","user":"anonymous","dateUpdated":"2019-07-22T14:40:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806386203_-2035590602","id":"20190722-143946_1797710960","dateCreated":"2019-07-22T14:39:46+0000","dateStarted":"2019-07-22T14:40:19+0000","dateFinished":"2019-07-22T14:40:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:181"},{"text":"val nb = new NaiveBayes()\n      .setModelType(\"multinomial\")\n\nval pipeline = new Pipeline()\n  .setStages(Array(hashingTF,idf, nb))\n\nval model = pipeline.fit(training)\n\nevaluate(model, test)","user":"anonymous","dateUpdated":"2019-07-22T14:40:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806253520_-1178908849","id":"20190722-143733_2029638280","dateCreated":"2019-07-22T14:37:33+0000","dateStarted":"2019-07-22T14:40:22+0000","dateFinished":"2019-07-22T14:40:24+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:182"},{"text":"%md\n#### Logistic Regression\nEn este entrenamiento se ha modificado la variable MaxIter que permite definir el número de iteracciones máximo que hará nuestro modelo para converger. Esta variable se ha ajustado de igual forma como se realizó en los desarrollos en Python.","user":"anonymous","dateUpdated":"2019-07-22T18:26:40+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Logistic Regression</h4>\n<p>En este entrenamiento se ha modificado la variable MaxIter que permite definir el número de iteracciones máximo que hará nuestro modelo para converger. Esta variable se ha ajustado de igual forma como se realizó en los desarrollos en Python.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806312080_-5729329","id":"20190722-143832_660565610","dateCreated":"2019-07-22T14:38:32+0000","dateStarted":"2019-07-22T18:26:40+0000","dateFinished":"2019-07-22T18:26:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:183"},{"text":"import org.apache.spark.ml.classification.LogisticRegression","user":"anonymous","dateUpdated":"2019-07-22T14:43:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806597980_1103235357","id":"20190722-144317_1440665567","dateCreated":"2019-07-22T14:43:17+0000","dateStarted":"2019-07-22T14:43:34+0000","dateFinished":"2019-07-22T14:43:37+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:184"},{"text":"val lr = new LogisticRegression()\n      .setMaxIter(100)\n\nval pipeline = new Pipeline()\n  .setStages(Array(hashingTF,idf, lr))\n\nval model = pipeline.fit(training)\n\nevaluate(model, test)","user":"anonymous","dateUpdated":"2019-07-22T14:45:01+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806627257_-1337866239","id":"20190722-144347_977088763","dateCreated":"2019-07-22T14:43:47+0000","dateStarted":"2019-07-22T14:45:01+0000","dateFinished":"2019-07-22T14:45:02+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:185"},{"text":"%md\n#### Random Forest\nEn este entrenamiento se ha modificado la variable NumTrees la cual controla el número de árboles que el algoritmo genera. Esta se ha configurado a 100 árboles utilizando la misma inicialización que el algoritmo en Python.","user":"anonymous","dateUpdated":"2019-07-22T18:28:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Random Forest</h4>\n<p>En este entrenamiento se ha modificado la variable NumTrees la cual controla el número de árboles que el algoritmo genera. Esta se ha configurado a 100 árboles utilizando la misma inicialización que el algoritmo en Python.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1563806705833_64200042","id":"20190722-144505_1578128843","dateCreated":"2019-07-22T14:45:05+0000","dateStarted":"2019-07-22T18:28:24+0000","dateFinished":"2019-07-22T18:28:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:186"},{"text":"import org.apache.spark.ml.classification.RandomForestClassifier","user":"anonymous","dateUpdated":"2019-07-22T14:46:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.classification.RandomForestClassifier\n"}]},"apps":[],"jobName":"paragraph_1563806613827_1075733674","id":"20190722-144333_1471231056","dateCreated":"2019-07-22T14:43:33+0000","dateStarted":"2019-07-22T14:46:34+0000","dateFinished":"2019-07-22T14:46:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:187"},{"text":"val rf = new RandomForestClassifier()\n      .setNumTrees(100)\n\nval pipeline = new Pipeline()\n  .setStages(Array(hashingTF,idf, rf))\n\nval model = pipeline.fit(training)\n\nevaluate(model, test)","user":"anonymous","dateUpdated":"2019-07-22T18:27:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1563806763785_-460432727","id":"20190722-144603_1880663618","dateCreated":"2019-07-22T14:46:03+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:189"}],"name":"Clasificación de Textos - Yelp","id":"2EFRZ9W5D","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"simple","personalizedMode":"false"},"info":{}}